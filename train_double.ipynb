{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61aa54ee-4dd2-4b11-8117-254c8dfc0d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from bouncing_ball.dataloaders.bouncing_data import BouncingBallDataLoader\n",
    "from kalman_vae import KalmanVariationalAutoencoder\n",
    "from natsort import natsorted\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de4a8694-c7ba-4a7b-83ae-0fd3fdc3df70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints/bouncing_ball_double_warmup-5\"\n",
    "warmup_epochs = 5\n",
    "device = torch.device(\"cuda:2\")\n",
    "symmetrize_covariance = True\n",
    "dtype = torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f8daea-0b5a-4ccc-aaf1-aa91851bd66f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483f0605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e5a5f53-5a05-41d9-b4c1-8978b7daa6e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_dataloader_train = BouncingBallDataLoader(\n",
    "    root_dir=\"bouncing_ball/datasets/bouncing-ball/train\"\n",
    ")\n",
    "_dataloader_test = BouncingBallDataLoader(\n",
    "    root_dir=\"bouncing_ball/datasets/bouncing-ball/test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2fb1320-a03c-4038-bb10-2421402e5189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sequence_first_collate_fn(batch):\n",
    "    data = torch.Tensor(np.stack(batch, axis=0))\n",
    "    # data.shape: [batch size, sequence length, channels, height, width]\n",
    "    # Reshape to [sequence length, batch size, channels, height, width]\n",
    "    data = data.permute(1, 0, 2, 3, 4)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b155c4-419a-4057-a178-87125d4254dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    _dataloader_train, batch_size=128, shuffle=True, collate_fn=sequence_first_collate_fn\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    _dataloader_test, batch_size=128, shuffle=True, collate_fn=sequence_first_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bb0006e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 128, 1, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader_train):\n",
    "    print(data.shape)\n",
    "    # To Float32\n",
    "    data = (data > 0.5).float()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ab50ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m kvae \u001b[38;5;241m=\u001b[39m \u001b[43mKalmanVariationalAutoencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mz_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbernoulli\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m----> 8\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data2/packages/anaconda3/envs/kvae_nk/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data2/packages/anaconda3/envs/kvae_nk/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/data2/packages/anaconda3/envs/kvae_nk/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/data2/packages/anaconda3/envs/kvae_nk/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/data2/packages/anaconda3/envs/kvae_nk/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data2/packages/anaconda3/envs/kvae_nk/lib/python3.10/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW"
     ]
    }
   ],
   "source": [
    "kvae = KalmanVariationalAutoencoder(\n",
    "    image_size=data.shape[3:],\n",
    "    image_channels=data.shape[2],\n",
    "    a_dim=2,\n",
    "    z_dim=4,\n",
    "    K=3,\n",
    "    decoder_type=\"bernoulli\",\n",
    ").to(dtype=dtype).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ff1e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(kvae.parameters(), lr=7e-3)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3ef58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_latest_checkpoint_index(pattern):\n",
    "    files = glob.glob(pattern)\n",
    "    if files:\n",
    "        return int(\n",
    "            max(files, key=lambda x: int(x.split(\"-\")[-1].split(\".\")[0]))\n",
    "            .split(\"-\")[-1]\n",
    "            .split(\".\")[0]\n",
    "        )\n",
    "    return None\n",
    "\n",
    "\n",
    "latest_index = find_latest_checkpoint_index(os.path.join(checkpoint_dir, \"state-*.pth\"))\n",
    "\n",
    "if latest_index is not None:\n",
    "    checkpoint = torch.load(os.path.join(checkpoint_dir, f\"state-{latest_index}.pth\"))\n",
    "    kvae.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    epoch_start = checkpoint[\"epoch\"] + 1\n",
    "    print(\"Loaded checkpoint at epoch {}\".format(latest_index))\n",
    "else:\n",
    "    epoch_start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb4435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = tqdm(range(epoch_start, 100))\n",
    "for epoch in p:\n",
    "    kvae.train()\n",
    "    learn_weight_model = epoch >= warmup_epochs\n",
    "    losses = []\n",
    "    for i, data in enumerate(dataloader_train):\n",
    "        data = (data > 0.5).to(dtype=dtype).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        elbo, info = kvae.elbo(data, learn_weight_model=learn_weight_model, symmetrize_covariance=symmetrize_covariance)\n",
    "        loss = -elbo\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        p.set_description(\n",
    "            f\"Train Epoch {epoch}, Batch {i}/{len(dataloader_train)}, Loss {loss.item()}\"\n",
    "        )\n",
    "    train_loss = sum(losses) / len(losses)\n",
    "\n",
    "    # Test\n",
    "    kvae.eval()\n",
    "    losses = []\n",
    "    for i, data in enumerate(dataloader_test):\n",
    "        data = (data > 0.5).to(dtype=dtype).to(device)\n",
    "        elbo, info = kvae.elbo(data, symmetrize_covariance=symmetrize_covariance)\n",
    "        loss = -elbo\n",
    "        losses.append(loss.item())\n",
    "        p.set_description(\n",
    "            f\"Test Epoch {epoch}, Batch {i}/{len(dataloader_test)}, Loss {loss.item()}\"\n",
    "        )\n",
    "\n",
    "    test_loss = sum(losses) / len(losses)\n",
    "    \n",
    "    if (epoch > 0) & (epoch % 20 == 0):\n",
    "        scheduler.step()\n",
    "\n",
    "    # Save\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": kvae.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"train_loss\": train_loss,\n",
    "            \"test_loss\": test_loss,\n",
    "        },\n",
    "        os.path.join(checkpoint_dir, f\"state-{epoch}.pth\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2478e-deb3-46fd-a916-8a2badf2b85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.linalg.svd(kvae.state_space_model.mat_A_K[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84cfad8-9665-49c5-993f-5feb19d1e6a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.linalg.svd(kvae.state_space_model.mat_A_K[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df0140-73ac-4331-882e-8ff191727bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.linalg.svd(kvae.state_space_model.mat_A_K[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276bdbf3-68df-47dd-ba25-b012e88d8232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kvae.state_space_model.mat_C_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589bb310-487d-4f4b-a718-ccdffc5d8132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.linalg.svd(kvae.state_space_model.mat_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb59c2-fabc-44d3-abb8-aa6f29df0332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.linalg.svd(kvae.state_space_model.mat_R)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kvae_nk]",
   "language": "python",
   "name": "conda-env-kvae_nk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
