{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cbdbd88-9026-4d3d-805e-072bf2b6289b",
   "metadata": {},
   "source": [
    "# Result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d446186-0027-47fe-8376-103e12073a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "from bouncing_ball.dataloaders.bouncing_data import BouncingBallDataLoader\n",
    "from kalman_vae import KalmanVariationalAutoencoder\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from natsort import natsorted\n",
    "from sample_control import SampleControl\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8cb57eb-54d1-48a9-ac0d-965c26b453ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtype = torch.float64\n",
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7da8605-427c-4eea-9a78-5d4595bfce3b",
   "metadata": {},
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd854f9-7a38-40f3-a8af-0670bf509e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_dataloader_test = BouncingBallDataLoader(\n",
    "    root_dir=\"bouncing_ball/datasets/bouncing-ball/test\"\n",
    ")\n",
    "\n",
    "\n",
    "def sequence_first_collate_fn(batch):\n",
    "    data = torch.Tensor(np.stack(batch, axis=0))\n",
    "    # data.shape: [batch size, sequence length, channels, height, width]\n",
    "    # Reshape to [sequence length, batch size, channels, height, width]\n",
    "    data = data.permute(1, 0, 2, 3, 4)\n",
    "    return data\n",
    "\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    _dataloader_test, batch_size=128, shuffle=True, collate_fn=sequence_first_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f10fa7a-7e8a-4155-9eee-4b7d770429cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for data in dataloader_test:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2657af98-e3eb-43fc-89dc-1ea5be2c4509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_length, batch_size, image_channels, *image_size = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f315b254-965a-40d8-87a4-09439aca41be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_paths = [\n",
    "    file\n",
    "    for file in natsorted(\n",
    "        glob.glob(\"checkpoints/experiment_20231110_220254/state-*.pth\")\n",
    "    )\n",
    "]\n",
    "checkpoint = torch.load(checkpoint_paths[-1], map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a7932d-0740-466d-aada-c668ec2cb617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kvae = KalmanVariationalAutoencoder(\n",
    "    image_size=image_size,\n",
    "    image_channels=image_channels,\n",
    "    a_dim=2,\n",
    "    z_dim=4,\n",
    "    K=3,\n",
    "    decoder_type=\"bernoulli\",\n",
    ").to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c94e3ca-fde9-4086-903f-aac4b62400ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kvae.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ce3cef-7456-4015-9272-7cb73d6cf1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_length = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5d802-6294-47f5-b29f-9ec5628be02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_continuous_mask(seq_length, mask_length, batch_size, device, dtype):\n",
    "    lst = [1.0] * seq_length\n",
    "    start_index = (seq_length - mask_length) // 2\n",
    "    for i in range(start_index, start_index + mask_length):\n",
    "        lst[i] = 0.0\n",
    "    return (\n",
    "        torch.tensor(lst)\n",
    "        .repeat(batch_size, 1)\n",
    "        .transpose(0, 1)\n",
    "        .to(device=device, dtype=dtype)\n",
    "    )\n",
    "\n",
    "def create_random_mask(seq_length, batch_size, mask_rate, device, dtype):\n",
    "    return (torch.rand((seq_length, batch_size), device=device) >= mask_rate).type(\n",
    "        device=device, dtype=dtype\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ec067-5553-4ad7-b33d-52245fe054c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9500179-ae0e-4d7f-ac0a-c3ebf7f60817",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c436927-2b51-4f08-92ad-841fac105b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kvae.eval()\n",
    "observation_mask = create_continuous_mask(data.shape[0], mask_length, data.shape[1])\n",
    "for i, data in enumerate(dataloader_test):\n",
    "    data = (data > 0.5).to(dtype=dtype, device=device)\n",
    "    elbo, info = kvae.elbo(\n",
    "        xs=data,\n",
    "        observation_mask=observation_mask,\n",
    "        sample_control=SampleControl(),\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e0aed-dbe5-4f5b-881c-0c0e45a00af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2836836-9492-4b0e-8a4d-2b4266bf07b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_images = (\n",
    "    kvae.decoder(info[\"filter_as\"].view(-1, 2))\n",
    "    .mean.view(seq_length, batch_size, *image.shape[-3:])\n",
    "    .cpu()\n",
    "    .float()\n",
    "    .detach()\n",
    "    .numpy()\n",
    ")\n",
    "smoothed_images = (\n",
    "    kvae.decoder(info[\"as_resampled\"].view(-1, 2))\n",
    "    .mean.view(seq_length, batch_size, *image.shape[-3:])\n",
    "    .cpu()\n",
    "    .float()\n",
    "    .detach()\n",
    "    .numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f524c-b69c-4ad4-8a19-75106203612f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "with TemporaryDirectory() as dname:\n",
    "    png_files = []\n",
    "    for step, (image) in enumerate((data)):\n",
    "        fig, axes = plt.subplots(figsize=(12, 4), nrows=1, ncols=3)\n",
    "        fig.suptitle(f\"$t = {step}$\")\n",
    "\n",
    "        image = (image > 0.5).cpu().float().detach().numpy()\n",
    "        red_grad = LinearSegmentedColormap.from_list(\n",
    "            \"red_grad\", [(1, 1, 1), (1, 0, 0)], N=256\n",
    "        )\n",
    "        black_grad = LinearSegmentedColormap.from_list(\n",
    "            \"black_grad\", [(1, 1, 1), (0, 0, 0)], N=256\n",
    "        )\n",
    "\n",
    "        axes[0].imshow(\n",
    "            image[idx][0], vmin=0, vmax=1, cmap=red_grad, aspect=\"equal\", alpha=0.5\n",
    "        )\n",
    "        axes[0].imshow(\n",
    "            filtered_images[step, idx, 0],\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            cmap=black_grad,\n",
    "            aspect=\"equal\",\n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "        axes[1].imshow(\n",
    "            image[idx][0], vmin=0, vmax=1, cmap=red_grad, aspect=\"equal\", alpha=0.5\n",
    "        )\n",
    "        axes[1].imshow(\n",
    "            smoothed_images[step, idx, 0],\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            cmap=black_grad,\n",
    "            aspect=\"equal\",\n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "        axes[2].plot(\n",
    "            info[\"as\"][:, idx, 0].cpu().detach().numpy(),\n",
    "            info[\"as\"][:, idx, 1].cpu().detach().numpy(),\n",
    "            \".-\",\n",
    "            color=cmap(0),\n",
    "            label=\"Encoded\",\n",
    "        )\n",
    "\n",
    "        axes[2].plot(\n",
    "            info[\"filter_as\"][:, idx, 0].cpu().detach().numpy(),\n",
    "            info[\"filter_as\"][:, idx, 1].cpu().detach().numpy(),\n",
    "            \".-\",\n",
    "            color=cmap(1),\n",
    "            label=\"Filtered\",\n",
    "        )\n",
    "\n",
    "        axes[2].plot(\n",
    "            info[\"as_resampled\"][:, idx, 0].cpu().detach().numpy(),\n",
    "            info[\"as_resampled\"][:, idx, 1].cpu().detach().numpy(),\n",
    "            \".-\",\n",
    "            color=cmap(2),\n",
    "            label=\"Smoothed\",\n",
    "        )\n",
    "\n",
    "        for key in (\"as\", \"filter_as\", \"as_resampled\"):\n",
    "            axes[2].plot(\n",
    "                info[key][step, idx, 0].cpu().detach().numpy(),\n",
    "                info[key][step, idx, 1].cpu().detach().numpy(),\n",
    "                \"o\",\n",
    "                markersize=8,\n",
    "                color=\"red\",\n",
    "                linestyle=\"none\",\n",
    "                zorder=10,\n",
    "            )\n",
    "\n",
    "        axes[2].plot(\n",
    "            (observation_mask.unsqueeze(-1) * info[\"as\"])[:, idx, 0]\n",
    "            .cpu()\n",
    "            .detach()\n",
    "            .numpy(),\n",
    "            (observation_mask.unsqueeze(-1) * info[\"as\"])[:, idx, 1]\n",
    "            .cpu()\n",
    "            .detach()\n",
    "            .numpy(),\n",
    "            \"s\",\n",
    "            color=\"black\",\n",
    "            label=\"Observed\",\n",
    "        )\n",
    "\n",
    "        axes[0].set_title(\"from filtered $\\\\mathbf{z}$\")\n",
    "        axes[1].set_title(\"from smoothed $\\\\mathbf{z}$\")\n",
    "        axes[2].set_title(\"$\\\\mathbf{a}$ space\")\n",
    "        axes[2].legend()\n",
    "        axes[2].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        png_file = os.path.join(dname, f\"{step}.png\")\n",
    "        plt.savefig(png_file)\n",
    "        png_files.append(png_file)\n",
    "        plt.close()\n",
    "    clip = ImageSequenceClip(png_files, fps=10)\n",
    "    clip.write_videofile(\"trajectory.mp4\", codec=\"libx264\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b47178-4312-499f-bb7f-23e67800330f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kalman-vae]",
   "language": "python",
   "name": "conda-env-kalman-vae-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
